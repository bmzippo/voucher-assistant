#!/usr/bin/env python3
"""
Vector Search Demo - TÃ¬m kiáº¿m voucher báº±ng semantic search
TÃ¬m kiáº¿m vá»›i tá»« khÃ³a: "quÃ¡n cafe cÃ³ khÃ´ng gian lÃ£ng máº¡n"
"""

import json
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer
from typing import List, Dict
import time
import os

class VoucherVectorSearchDemo:
    def __init__(self):
        self.es_url = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
        self.index_name = os.getenv("ELASTICSEARCH_INDEX", "voucher_knowledge")
        self.model_name = os.getenv("EMBEDDING_MODEL", "keepitreal/vietnamese-sbert")
        
        # Initialize components
        self.es = Elasticsearch([self.es_url], verify_certs=False, request_timeout=30)
        self.model = SentenceTransformer(self.model_name)
        
        print(f"ðŸ”§ Connected to Elasticsearch: {self.es_url}")
        print(f"ðŸ¤– Loaded embedding model: {self.model_name}")

    def create_query_embedding(self, query: str) -> List[float]:
        """Táº¡o vector embedding cho cÃ¢u query"""
        print(f"\nðŸ“ Creating embedding for query: '{query}'")
        start_time = time.time()
        
        embedding = self.model.encode(query)
        embedding_time = time.time() - start_time
        
        print(f"â±ï¸  Embedding creation time: {embedding_time:.3f}s")
        print(f"ðŸ“Š Embedding vector dimensions: {len(embedding)}")
        print(f"ðŸ”¢ Sample embedding values: {embedding[:5].tolist()}")
        
        return embedding.tolist()

    def semantic_search(self, query: str, size: int = 5, min_score: float = 0.7) -> Dict:
        """Thá»±c hiá»‡n semantic search sá»­ dá»¥ng vector similarity"""
        print(f"\nðŸ” Starting semantic search...")
        print(f"ðŸ“‹ Search parameters:")
        print(f"   - Query: '{query}'")
        print(f"   - Results size: {size}")
        print(f"   - Minimum score: {min_score}")
        
        # BÆ°á»›c 1: Táº¡o embedding cho query
        query_embedding = self.create_query_embedding(query)
        
        # BÆ°á»›c 2: XÃ¢y dá»±ng Elasticsearch query
        search_query = {
            "size": size,
            "min_score": min_score,
            "_source": [
                "voucher_id", 
                "voucher_name", 
                "content", 
                "merchant", 
                "metadata.price",
                "metadata.location",
                "metadata.source_file"
            ],
            "query": {
                "script_score": {
                    "query": {"match_all": {}},
                    "script": {
                        "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                        "params": {"query_vector": query_embedding}
                    }
                }
            }
        }
        
        print(f"\nðŸ”§ Elasticsearch query structure:")
        print(f"   - Using script_score with cosine similarity")
        print(f"   - Query vector size: {len(query_embedding)}")
        
        # BÆ°á»›c 3: Thá»±c hiá»‡n search
        search_start = time.time()
        try:
            response = self.es.search(index=self.index_name, body=search_query)
            search_time = time.time() - search_start
            
            print(f"\nâš¡ Search completed in {search_time:.3f}s")
            print(f"ðŸ“Š Total hits: {response['hits']['total']['value']}")
            print(f"ðŸŽ¯ Results returned: {len(response['hits']['hits'])}")
            
            return response
            
        except Exception as e:
            print(f"âŒ Search error: {e}")
            return {}

    def analyze_results(self, response: Dict, query: str):
        """PhÃ¢n tÃ­ch chi tiáº¿t káº¿t quáº£ tÃ¬m kiáº¿m"""
        if not response or 'hits' not in response:
            print("âŒ No results to analyze")
            return
            
        hits = response['hits']['hits']
        
        print(f"\nðŸ“Š DETAILED ANALYSIS OF SEARCH RESULTS")
        print(f"=" * 60)
        print(f"ðŸ” Query: '{query}'")
        print(f"ðŸ“ˆ Total documents in index: {response['hits']['total']['value']}")
        print(f"ðŸŽ¯ Results matching criteria: {len(hits)}")
        
        if not hits:
            print("âŒ No results found matching the minimum score threshold")
            return
            
        print(f"\nðŸ† TOP RESULTS:")
        print("-" * 60)
        
        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            score = hit['_score']
            
            print(f"\n#{i} - Score: {score:.4f}")
            print(f"ðŸ“› Voucher: {source.get('voucher_name', 'N/A')}")
            print(f"ðŸª Merchant: {source.get('merchant', 'N/A')}")
            print(f"ðŸ’° Price: {source.get('metadata', {}).get('price', 'N/A'):,}Ä‘")
            print(f"ðŸ“ Location: {source.get('metadata', {}).get('location', 'N/A')}")
            print(f"ðŸ“ Source: {source.get('metadata', {}).get('source_file', 'N/A')}")
            
            # Hiá»ƒn thá»‹ ná»™i dung (giá»›i háº¡n 200 kÃ½ tá»±)
            content = source.get('content', '')
            if len(content) > 200:
                content = content[:200] + "..."
            print(f"ðŸ“„ Content: {content}")
            
            # PhÃ¢n tÃ­ch Ä‘á»™ liÃªn quan
            self._analyze_relevance(source, query, score)
            print("-" * 40)

    def _analyze_relevance(self, source: Dict, query: str, score: float):
        """PhÃ¢n tÃ­ch táº¡i sao káº¿t quáº£ nÃ y liÃªn quan Ä‘áº¿n query"""
        content = source.get('content', '').lower()
        voucher_name = source.get('voucher_name', '').lower()
        
        # Keywords tá»« query
        query_keywords = ['cafe', 'quÃ¡n', 'khÃ´ng gian', 'lÃ£ng máº¡n', 'coffee']
        
        matched_keywords = []
        for keyword in query_keywords:
            if keyword in content or keyword in voucher_name:
                matched_keywords.append(keyword)
        
        print(f"ðŸŽ¯ Relevance Analysis:")
        print(f"   - Similarity score: {score:.4f}")
        print(f"   - Matched keywords: {matched_keywords if matched_keywords else 'None (semantic similarity)'}")
        
        # ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ phÃ¹ há»£p
        if score >= 1.8:
            relevance = "ðŸŸ¢ Highly Relevant"
        elif score >= 1.6:
            relevance = "ðŸŸ¡ Moderately Relevant" 
        elif score >= 1.4:
            relevance = "ðŸŸ  Somewhat Relevant"
        else:
            relevance = "ðŸ”´ Low Relevance"
            
        print(f"   - Assessment: {relevance}")

    def run_demo(self):
        """Cháº¡y demo tÃ¬m kiáº¿m"""
        print("ðŸš€ VECTOR SEARCH DEMO - VOUCHER AI ASSISTANT")
        print("=" * 60)
        
        # Query test
        test_query = "quÃ¡n cafe cÃ³ khÃ´ng gian lÃ£ng máº¡n"
        
        print(f"ðŸŽ¯ Test case: Searching for '{test_query}'")
        print("ðŸ“ Expected results: Cafe/coffee vouchers with romantic ambiance")
        
        # Thá»±c hiá»‡n tÃ¬m kiáº¿m
        results = self.semantic_search(test_query, size=10, min_score=0.5)
        
        # PhÃ¢n tÃ­ch káº¿t quáº£
        self.analyze_results(results, test_query)
        
        # TÃ³m táº¯t insights
        self._provide_insights(results, test_query)

    def _provide_insights(self, response: Dict, query: str):
        """Cung cáº¥p insights vá» káº¿t quáº£ tÃ¬m kiáº¿m"""
        if not response or 'hits' not in response:
            return
            
        hits = response['hits']['hits']
        
        print(f"\nðŸ’¡ SEARCH INSIGHTS & RECOMMENDATIONS")
        print("=" * 60)
        
        if not hits:
            print("ðŸ” No results found. Suggestions:")
            print("   - Try broader keywords like 'cafe' or 'coffee'")
            print("   - Lower the minimum score threshold")
            print("   - Check if relevant vouchers exist in the database")
            return
        
        # PhÃ¢n tÃ­ch merchants
        merchants = {}
        locations = {}
        avg_price = 0
        total_price_count = 0
        
        for hit in hits:
            source = hit['_source']
            merchant = source.get('merchant', 'Unknown')
            location = source.get('metadata', {}).get('location', 'Unknown')
            price = source.get('metadata', {}).get('price', 0)
            
            merchants[merchant] = merchants.get(merchant, 0) + 1
            locations[location] = locations.get(location, 0) + 1
            
            if price > 0:
                avg_price += price
                total_price_count += 1
        
        print(f"ðŸ“Š Results Statistics:")
        print(f"   - Total relevant vouchers: {len(hits)}")
        if total_price_count > 0:
            print(f"   - Average voucher value: {avg_price/total_price_count:,.0f}Ä‘")
        
        print(f"\nðŸª Top Merchants:")
        for merchant, count in sorted(merchants.items(), key=lambda x: x[1], reverse=True)[:3]:
            print(f"   - {merchant}: {count} vouchers")
            
        print(f"\nðŸ“ Locations:")
        for location, count in sorted(locations.items(), key=lambda x: x[1], reverse=True)[:3]:
            print(f"   - {location}: {count} vouchers")
        
        print(f"\nðŸŽ¯ Search Quality Assessment:")
        high_quality = sum(1 for hit in hits if hit['_score'] >= 1.7)
        medium_quality = sum(1 for hit in hits if 1.5 <= hit['_score'] < 1.7)
        low_quality = len(hits) - high_quality - medium_quality
        
        print(f"   - High relevance (â‰¥1.7): {high_quality} results")
        print(f"   - Medium relevance (1.5-1.7): {medium_quality} results")
        print(f"   - Lower relevance (<1.5): {low_quality} results")

if __name__ == "__main__":
    demo = VoucherVectorSearchDemo()
    demo.run_demo()
