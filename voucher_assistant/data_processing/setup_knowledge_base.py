#!/usr/bin/env python3
"""
OneU AI Voucher Assistant - Knowledge Base Setup
Thiáº¿t láº­p knowledge base tá»« dá»¯ liá»‡u voucher Excel
"""

import sys
import os

# Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t dependencies
def check_and_install_dependencies():
    """Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t"""
    required_packages = [
        'pandas',
        'numpy', 
        'elasticsearch>=8.0.0,<9.0.0',  # Fix version compatibility
        'sentence-transformers',
        'openpyxl',
        'python-dotenv',
        'requests'
    ]
    
    missing_packages = []
    
    # Kiá»ƒm tra tá»«ng package
    for package in required_packages:
        package_name = package.split('>=')[0].split('==')[0].replace('-', '_')
        try:
            __import__(package_name)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ Thiáº¿u cÃ¡c thÆ° viá»‡n: {', '.join(missing_packages)}")
        print("ğŸ”§ Äang cÃ i Ä‘áº·t dependencies...")
        
        import subprocess
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", 
                *missing_packages
            ])
            print("âœ… CÃ i Ä‘áº·t thÃ nh cÃ´ng!")
        except subprocess.CalledProcessError:
            print("âŒ Lá»—i cÃ i Ä‘áº·t. Vui lÃ²ng cháº¡y:")
            print(f"pip install {' '.join(missing_packages)}")
            sys.exit(1)

# Kiá»ƒm tra dependencies trÆ°á»›c khi import
check_and_install_dependencies()

try:
    import pandas as pd
    import numpy as np
    from elasticsearch import Elasticsearch
    from sentence_transformers import SentenceTransformer
    import json
    import logging
    from dotenv import load_dotenv
    import time
    import requests
    import warnings
    
    # Suppress Elasticsearch warnings
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    
except ImportError as e:
    print(f"âŒ Lá»—i import: {e}")
    print("ğŸ”§ Vui lÃ²ng cháº¡y: pip install -r requirements.txt")
    sys.exit(1)

# Load environment variables
load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class VoucherKnowledgeBaseSetup:
    def __init__(self):
        self.es_host = os.getenv('ELASTICSEARCH_HOST', 'localhost:9200')
        self.es_index = os.getenv('ELASTICSEARCH_INDEX', 'voucher_knowledge_base')
        self.model_name = os.getenv('EMBEDDING_MODEL', 'dangvantuan/vietnamese-embedding')
        self.embedding_dimension = int(os.getenv('EMBEDDING_DIMENSION', '768'))  # Default to 768 for Vietnamese model
        
        # Initialize components
        self.es = None
        self.model = None
        self.actual_embedding_dimension = None
        
    def wait_for_elasticsearch(self, max_retries=30):
        """Äá»£i Elasticsearch khá»Ÿi Ä‘á»™ng"""
        logger.info("ğŸ” Äang kiá»ƒm tra Elasticsearch...")
        
        for i in range(max_retries):
            try:
                response = requests.get(f"http://{self.es_host}/_cluster/health", timeout=5)
                if response.status_code == 200:
                    logger.info("âœ… Elasticsearch Ä‘Ã£ sáºµn sÃ ng!")
                    return True
            except requests.RequestException:
                pass
            
            logger.info(f"â³ Äang Ä‘á»£i Elasticsearch... ({i+1}/{max_retries})")
            time.sleep(2)
        
        logger.error("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i Elasticsearch")
        return False
    
    def setup_elasticsearch(self):
        """Thiáº¿t láº­p káº¿t ná»‘i Elasticsearch vá»›i version compatibility"""
        if not self.wait_for_elasticsearch():
            logger.error("âŒ Elasticsearch khÃ´ng kháº£ dá»¥ng")
            return False
            
        try:
            # Táº¡o Elasticsearch client vá»›i cáº¥u hÃ¬nh phÃ¹ há»£p
            self.es = Elasticsearch(
                [f"http://{self.es_host}"],
                verify_certs=False,
                request_timeout=30,
                retry_on_timeout=True,
                max_retries=3
            )
            
            # Test connection vá»›i error handling
            try:
                info = self.es.info()
                version = info.get('version', {}).get('number', 'unknown')
                logger.info(f"âœ… Káº¿t ná»‘i Elasticsearch thÃ nh cÃ´ng: v{version}")
                return True
            except Exception as version_error:
                logger.warning(f"âš ï¸ Version check failed: {version_error}")
                # Try basic ping instead
                if self.es.ping():
                    logger.info("âœ… Káº¿t ná»‘i Elasticsearch thÃ nh cÃ´ng (basic ping)")
                    return True
                else:
                    raise Exception("Ping failed")
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i káº¿t ná»‘i Elasticsearch: {e}")
            logger.info("ğŸ”§ Thá»­ sá»­ dá»¥ng phiÃªn báº£n Elasticsearch client tÆ°Æ¡ng thÃ­ch...")
            
            # Try with legacy client configuration
            try:
                self.es = Elasticsearch(
                    [{'host': 'localhost', 'port': 9200}],
                    verify_certs=False,
                    timeout=30
                )
                
                if self.es.ping():
                    logger.info("âœ… Káº¿t ná»‘i Elasticsearch thÃ nh cÃ´ng (legacy mode)")
                    return True
                    
            except Exception as legacy_error:
                logger.error(f"âŒ Legacy connection failed: {legacy_error}")
                
            return False
    
    def setup_embedding_model(self):
        """Thiáº¿t láº­p model embedding"""
        try:
            logger.info(f"ğŸ¤– Äang táº£i model embedding: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            
            # Test model Ä‘á»ƒ láº¥y actual dimension
            test_embedding = self.model.encode("test")
            self.actual_embedding_dimension = len(test_embedding)
            logger.info(f"âœ… Model embedding Ä‘Ã£ sáºµn sÃ ng! Dimension: {self.actual_embedding_dimension}")
            
            # Update embedding dimension náº¿u khÃ¡c vá»›i config
            if self.actual_embedding_dimension != self.embedding_dimension:
                logger.info(f"ğŸ”„ Cáº­p nháº­t embedding dimension tá»« {self.embedding_dimension} thÃ nh {self.actual_embedding_dimension}")
                self.embedding_dimension = self.actual_embedding_dimension
            
            return True
        except Exception as e:
            logger.error(f"âŒ Lá»—i táº£i model: {e}")
            return False
    
    def create_index_mapping(self):
        """Táº¡o mapping cho Elasticsearch index vá»›i version compatibility"""
        mapping = {
            "mappings": {
                "properties": {
                    "voucher_id": {"type": "keyword"},
                    "voucher_name": {
                        "type": "text", 
                        "analyzer": "standard",
                        "fields": {
                            "keyword": {"type": "keyword"}
                        }
                    },
                    "content": {
                        "type": "text", 
                        "analyzer": "standard"
                    },
                    "content_type": {"type": "keyword"},
                    "embedding": {
                        "type": "dense_vector",
                        "dims": self.embedding_dimension,  # Use actual dimension from model
                        "index": True,
                        "similarity": "cosine"
                    },
                    "metadata": {"type": "object"},
                    "created_at": {"type": "date"}
                }
            },
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 0
            }
        }
        
        try:
            # XÃ³a index cÅ© náº¿u tá»“n táº¡i
            if self.es.indices.exists(index=self.es_index):
                self.es.indices.delete(index=self.es_index)
                logger.info(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a index cÅ©: {self.es_index}")
            
            # Táº¡o index má»›i
            response = self.es.indices.create(index=self.es_index, body=mapping)
            logger.info(f"âœ… ÄÃ£ táº¡o index: {self.es_index} vá»›i dimension: {self.embedding_dimension}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i táº¡o index: {e}")
            
            # Try with simpler mapping if advanced features fail
            try:
                simple_mapping = {
                    "mappings": {
                        "properties": {
                            "voucher_id": {"type": "keyword"},
                            "voucher_name": {"type": "text"},
                            "content": {"type": "text"},
                            "content_type": {"type": "keyword"},
                            "embedding": {
                                "type": "dense_vector",
                                "dims": self.embedding_dimension  # Use actual dimension
                            },
                            "metadata": {"type": "object"},
                            "created_at": {"type": "date"}
                        }
                    }
                }
                
                response = self.es.indices.create(index=self.es_index, body=simple_mapping)
                logger.info(f"âœ… ÄÃ£ táº¡o index vá»›i simple mapping: {self.es_index} (dims: {self.embedding_dimension})")
                return True
                
            except Exception as simple_error:
                logger.error(f"âŒ Lá»—i táº¡o simple index: {simple_error}")
                return False
    
    def load_voucher_data(self):
        """Táº£i dá»¯ liá»‡u voucher tá»« Excel file"""
        # TÃ¬m file Excel trong cÃ¡c Ä‘Æ°á»ng dáº«n cÃ³ thá»ƒ
        possible_paths = [
            "../data/temp voucher.xlsx",
            "./data/temp voucher.xlsx", 
            "../temp voucher.xlsx",
            "./temp voucher.xlsx",
            "temp voucher.xlsx"
        ]
        
        excel_file = None
        for path in possible_paths:
            if os.path.exists(path):
                excel_file = path
                break
        
        if not excel_file:
            logger.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y file Excel trong cÃ¡c Ä‘Æ°á»ng dáº«n: {possible_paths}")
            logger.info("ğŸ’¡ Vui lÃ²ng Ä‘áº·t file 'temp voucher.xlsx' trong thÆ° má»¥c data/")
            return None
        
        try:
            df = pd.read_excel(excel_file)
            logger.info(f"âœ… ÄÃ£ táº£i {len(df)} vouchers tá»« {excel_file}")
            
            # In thÃ´ng tin cá»™t Ä‘á»ƒ debug
            logger.info(f"ğŸ“‹ CÃ¡c cá»™t trong Excel: {list(df.columns)}")
            return df
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i Ä‘á»c Excel: {e}")
            return None
    
    def process_and_index_vouchers(self, df):
        """Xá»­ lÃ½ vÃ  index vouchers vÃ o Elasticsearch"""
        logger.info("ğŸ”„ Báº¯t Ä‘áº§u xá»­ lÃ½ vÃ  index vouchers...")
        
        total_docs = 0
        
        for idx, row in df.iterrows():
            try:
                voucher_id = f"voucher_{idx}"
                
                # Láº¥y tÃªn voucher tá»« cÃ¡c cá»™t cÃ³ thá»ƒ
                voucher_name = None
                for col_name in ['TÃªn voucher', 'Voucher Name', 'Name', 'Title']:
                    if col_name in df.columns and pd.notna(row.get(col_name)):
                        voucher_name = str(row[col_name])
                        break
                
                if not voucher_name:
                    voucher_name = f'Voucher {idx + 1}'
                
                # Táº¡o ná»™i dung tá»« cÃ¡c cá»™t
                content_parts = []
                for col in df.columns:
                    if pd.notna(row[col]) and str(row[col]).strip():
                        content_parts.append(f"{col}: {str(row[col]).strip()}")
                
                content = " | ".join(content_parts)
                
                # Äáº£m báº£o content khÃ´ng rá»—ng
                if not content.strip():
                    logger.warning(f"âš ï¸ Voucher {idx} cÃ³ ná»™i dung rá»—ng, bá» qua")
                    continue
                
                # Táº¡o embedding
                try:
                    embedding = self.model.encode(content).tolist()
                except Exception as embed_error:
                    logger.error(f"âŒ Lá»—i táº¡o embedding cho voucher {idx}: {embed_error}")
                    continue
                
                # Táº¡o document
                doc = {
                    "voucher_id": voucher_id,
                    "voucher_name": voucher_name,
                    "content": content,
                    "content_type": "voucher_details",
                    "embedding": embedding,
                    "metadata": {
                        "source": "temp_voucher.xlsx",
                        "row_index": idx,
                        "total_columns": len(df.columns)
                    },
                    "created_at": pd.Timestamp.now().isoformat()
                }
                
                # Index document
                self.es.index(index=self.es_index, id=voucher_id, document=doc)
                total_docs += 1
                
                if (idx + 1) % 5 == 0 or idx + 1 == len(df):
                    logger.info(f"ğŸ“ ÄÃ£ xá»­ lÃ½ {idx + 1}/{len(df)} vouchers")
                    
            except Exception as e:
                logger.error(f"âŒ Lá»—i xá»­ lÃ½ voucher {idx}: {e}")
                continue
        
        logger.info(f"âœ… HoÃ n thÃ nh! ÄÃ£ index {total_docs} documents")
        return total_docs
    
    def verify_setup(self):
        """Kiá»ƒm tra setup"""
        try:
            # Refresh index
            self.es.indices.refresh(index=self.es_index)
            
            # Äáº¿m documents
            count_response = self.es.count(index=self.es_index)
            count = count_response['count']
            logger.info(f"ğŸ“Š Tá»•ng sá»‘ documents trong index: {count}")
            
            if count == 0:
                logger.warning("âš ï¸ KhÃ´ng cÃ³ documents nÃ o trong index")
                return False
            
            # Test search
            test_query = {
                "query": {
                    "match_all": {}
                },
                "size": 1
            }
            
            result = self.es.search(index=self.es_index, body=test_query)
            if result['hits']['total']['value'] > 0:
                logger.info("âœ… Test search thÃ nh cÃ´ng!")
                
                # In thÃ´ng tin sample document
                sample_doc = result['hits']['hits'][0]['_source']
                logger.info(f"ğŸ“„ Sample document: {sample_doc['voucher_name']}")
                return True
            else:
                logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ test search")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Lá»—i verification: {e}")
            return False
    
    def run_setup(self):
        """Cháº¡y toÃ n bá»™ setup process"""
        logger.info("ğŸš€ Báº¯t Ä‘áº§u setup Knowledge Base cho OneU AI Voucher Assistant")
        
        # 1. Setup Elasticsearch
        if not self.setup_elasticsearch():
            return False
        
        # 2. Setup embedding model
        if not self.setup_embedding_model():
            return False
        
        # 3. Táº¡o index mapping
        if not self.create_index_mapping():
            return False
        
        # 4. Load voucher data
        df = self.load_voucher_data()
        if df is None:
            return False
        
        # 5. Process vÃ  index vouchers
        docs_count = self.process_and_index_vouchers(df)
        if docs_count == 0:
            return False
        
        # 6. Verify setup
        if not self.verify_setup():
            return False
        
        logger.info("ğŸ‰ Setup Knowledge Base hoÃ n thÃ nh thÃ nh cÃ´ng!")
        return True

def main():
    """Main function"""
    setup = VoucherKnowledgeBaseSetup()
    
    if setup.run_setup():
        print("\nğŸ‰ OneU AI Voucher Assistant Knowledge Base Ä‘Ã£ sáºµn sÃ ng!")
        print(f"ğŸ“Š Index: {setup.es_index}")
        print(f"ğŸ” Elasticsearch: http://{setup.es_host}")
        print("\nğŸš€ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y backend API!")
        print("\nğŸ“ Äá»ƒ test knowledge base:")
        print("   curl http://localhost:8000/api/search?q=voucher")
    else:
        print("\nâŒ Setup tháº¥t báº¡i. Vui lÃ²ng kiá»ƒm tra logs vÃ  thá»­ láº¡i.")
        sys.exit(1)

if __name__ == "__main__":
    main()