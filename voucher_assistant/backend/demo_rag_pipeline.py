#!/usr/bin/env python3
"""
Demo script for Voucher AI Assistant RAG Pipeline
Showcases the complete Retrieval + Generation system
"""

import asyncio
import sys
import os
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent))

from advanced_vector_store import AdvancedVectorStore
import logging

# Configure logging
logging.basicConfig(level=logging.WARNING)  # Reduce noise for demo

def print_header(title):
    """Print formatted header"""
    print("\n" + "=" * 60)
    print(f"üéØ {title}")
    print("=" * 60)

def print_rag_response(response, query):
    """Print formatted RAG response"""
    print(f"‚ùì **C√¢u h·ªèi**: {query}")
    print(f"‚è±Ô∏è  **Th·ªùi gian x·ª≠ l√Ω**: {response.processing_time:.2f}s")
    print(f"üéØ **ƒê·ªô tin c·∫≠y**: {response.confidence_score:.3f}")
    print(f"üìä **S·ªë voucher t√¨m th·∫•y**: {len(response.retrieved_vouchers)}")
    
    if response.query_intent:
        print("üß† **Ph√¢n t√≠ch √Ω ƒë·ªãnh**:")
        for intent, score in response.query_intent.items():
            if score and score != 'unknown':
                print(f"   ‚Ä¢ {intent}: {score}")
    
    print("\nü§ñ **C√¢u tr·∫£ l·ªùi AI**:")
    print("-" * 40)
    print(response.answer)
    print("-" * 40)
    
    if response.retrieved_vouchers:
        print(f"\nüìã **Top 3 voucher ph√π h·ª£p**:")
        for i, voucher in enumerate(response.retrieved_vouchers[:3], 1):
            print(f"\n   {i}. **{voucher.get('voucher_name', 'N/A')}**")
            print(f"      üìç ƒê·ªãa ƒëi·ªÉm: {voucher.get('location', {}).get('name', 'N/A')}")
            print(f"      üè™ D·ªãch v·ª•: {voucher.get('service_info', {}).get('category', 'N/A')}")
            print(f"      ‚≠ê ƒê·ªô ph√π h·ª£p: {voucher.get('similarity_score', 0):.1f}%")

async def demo_rag_pipeline():
    """Interactive demo of the RAG pipeline"""
    
    print_header("VOUCHER AI ASSISTANT - RAG PIPELINE DEMO")
    print("ü§ñ Tr·ª£ l√Ω AI th√¥ng minh cho voucher  ")
    print("üß† Powered by Advanced Vector Search + LLM Integration")
    
    # Initialize vector store
    vector_store = AdvancedVectorStore(index_name="voucher_knowledge")
    
    # Wait for system to be ready
    await asyncio.sleep(1)
    
    # Demo scenarios showcasing different capabilities
    demo_scenarios = [
        {
            "title": "T√¨m ki·∫øm theo Location + Service + Target",
            "query": "T√¥i mu·ªën t√¨m voucher buffet ·ªü H√† N·ªôi cho gia ƒë√¨nh 4 ng∆∞·ªùi",
            "description": "Demonstrates multi-intent processing with location, service type, and target audience"
        },
        {
            "title": "T√¨m ki·∫øm theo Service + Price Consideration", 
            "query": "C√≥ voucher massage spa n√†o kh√¥ng qu√° ƒë·∫Øt kh√¥ng?",
            "description": "Shows service-specific search with price sensitivity"
        },
        {
            "title": "T√¨m ki·∫øm theo Target Audience",
            "query": "Voucher n√†o ph√π h·ª£p cho h·∫πn h√≤ l√£ng m·∫°n?",
            "description": "Focuses on target audience and romantic context"
        },
        {
            "title": "T√¨m ki·∫øm c·ª• th·ªÉ h·∫£i s·∫£n",
            "query": "T√¥i mu·ªën ƒÉn buffet h·∫£i s·∫£n ·ªü TP.HCM",
            "description": "Specific food type with location targeting"
        },
        {
            "title": "T√¨m ki·∫øm trending vouchers",
            "query": "Voucher khuy·∫øn m√£i g√¨ hot nh·∫•t hi·ªán t·∫°i?",
            "description": "General trending query for popular offers"
        }
    ]
    
    print(f"\nüé¨ **DEMO: {len(demo_scenarios)} t√¨nh hu·ªëng th·ª±c t·∫ø**\n")
    
    # Run demo scenarios
    for i, scenario in enumerate(demo_scenarios, 1):
        print_header(f"SCENARIO {i}: {scenario['title']}")
        print(f"üìù **M√¥ t·∫£**: {scenario['description']}")
        
        try:
            # Get RAG response
            response = await vector_store.rag_search_with_llm(
                query=scenario['query'],
                top_k=5
            )
            
            # Display results
            print_rag_response(response, scenario['query'])
            
        except Exception as e:
            print(f"‚ùå **L·ªói**: {e}")
        
        # Pause between scenarios
        if i < len(demo_scenarios):
            print("\n" + "‚è≥ Processing next scenario..." + "\n")
            await asyncio.sleep(2)
    
    # Interactive section
    print_header("INTERACTIVE MODE")
    print("üí¨ **Th·ª≠ nghi·ªám c√¢u h·ªèi c·ªßa ri√™ng b·∫°n**")
    print("üö™ **G√µ 'exit' ƒë·ªÉ tho√°t**\n")
    
    while True:
        try:
            # Get user input
            user_query = input("‚ùì **C√¢u h·ªèi c·ªßa b·∫°n**: ").strip()
            
            if user_query.lower() in ['exit', 'quit', 'tho√°t']:
                print("üëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng Voucher AI Assistant!")
                break
            
            if not user_query:
                print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
                continue
            
            print("\nüîç **ƒêang x·ª≠ l√Ω...**")
            
            # Get RAG response
            response = await vector_store.rag_search_with_llm(query=user_query)
            
            # Display results
            print_rag_response(response, user_query)
            print("\n" + "-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\nüëã Demo ƒë√£ ƒë∆∞·ª£c d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            break
        except Exception as e:
            print(f"‚ùå **L·ªói**: {e}")
            print("üîÑ Vui l√≤ng th·ª≠ l·∫°i.\n")

async def quick_demo():
    """Quick demo showing key capabilities"""
    
    print_header("QUICK DEMO - Key RAG Capabilities")
    
    vector_store = AdvancedVectorStore(index_name="voucher_knowledge")
    await asyncio.sleep(1)
    
    # Quick test query
    test_query = "T√¨m voucher buffet h·∫£i s·∫£n cho gia ƒë√¨nh ·ªü H·ªì Ch√≠ Minh"
    
    print(f"üéØ **Test Query**: {test_query}")
    print("üîç **Processing...**\n")
    
    response = await vector_store.rag_search_with_llm(query=test_query)
    
    # Quick summary
    print("üìä **QUICK RESULTS SUMMARY**:")
    print(f"   ‚è±Ô∏è  Processing: {response.processing_time:.2f}s")
    print(f"   üéØ Confidence: {response.confidence_score:.3f}")
    print(f"   üìà Results: {len(response.retrieved_vouchers)} vouchers")
    print(f"   üîç Method: {response.search_method}")
    
    print(f"\nü§ñ **AI Response Preview**:")
    preview = response.answer[:150] + "..." if len(response.answer) > 150 else response.answer
    print(f"   {preview}")
    
    print(f"\n‚úÖ **RAG Pipeline Status: OPERATIONAL**")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Voucher AI Assistant RAG Demo")
    parser.add_argument("--quick", action="store_true", help="Run quick demo")
    parser.add_argument("--full", action="store_true", help="Run full interactive demo")
    
    args = parser.parse_args()
    
    if args.quick:
        asyncio.run(quick_demo())
    elif args.full:
        asyncio.run(demo_rag_pipeline())
    else:
        # Default: run quick demo
        print("üöÄ **Running Quick Demo** (use --full for interactive mode)")
        asyncio.run(quick_demo())
